{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QAGNN Phase 2: Deep Learning Model Training\n",
    "## üéØ Target: R¬≤ > 0.92 accuracy prediction\n",
    "\n",
    "This notebook trains a neural network to predict genetic circuit accuracy from design parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Setup\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory Free: {torch.cuda.mem_get_info()[0]/1e9:.1f} GB\")\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Verify Phase 1 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_phase1_data():\n",
    "    \"\"\"Verify Phase 1 data exists and is correct\"\"\"\n",
    "    print(\"üîç Verifying Phase 1 data...\")\n",
    "    \n",
    "    datasets = ['train', 'val', 'test']\n",
    "    for name in datasets:\n",
    "        path = f'../data/processed/{name}_dataset.h5'\n",
    "        if Path(path).exists():\n",
    "            with h5py.File(path, 'r') as f:\n",
    "                X = f['X'][:]\n",
    "                y = f['y'][:]\n",
    "                print(f\"‚úÖ {name}: {X.shape} samples, y-range: {y.min():.3f}-{y.max():.3f}\")\n",
    "        else:\n",
    "            print(f\"‚ùå {name}: Missing!\")\n",
    "            return False\n",
    "    \n",
    "    print(\"\\nüìä Data statistics:\")\n",
    "    with h5py.File('../data/processed/train_dataset.h5', 'r') as f:\n",
    "        X_train = f['X'][:]\n",
    "        y_train = f['y'][:]\n",
    "        \n",
    "    print(f\"   Features per sample: {X_train.shape[1]}\")\n",
    "    print(f\"   Feature range: {X_train.min():.3f} to {X_train.max():.3f}\")\n",
    "    print(f\"   Label range: {y_train.min():.3f} to {y_train.max():.3f}\")\n",
    "    print(f\"   Feature mean: {X_train.mean():.3f}, std: {X_train.std():.3f}\")\n",
    "    print(f\"   Label mean: {y_train.mean():.3f}, std: {y_train.std():.3f}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Run verification\n",
    "if verify_phase1_data():\n",
    "    print(\"\\n‚úÖ Phase 1 data verified successfully!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Phase 1 data verification failed!\")\n",
    "    print(\"   Restore from backup: ~/project_backups/qagnn_phase1_complete_*/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "from src.ai.data_loader import load_datasets\n",
    "\n",
    "train_loader, val_loader, test_loader, (X_test, y_test) = load_datasets(batch_size=32)\n",
    "\n",
    "# Get one batch\n",
    "for X_batch, y_batch in train_loader:\n",
    "    print(f\"First batch shape: X={X_batch.shape}, y={y_batch.shape}\")\n",
    "    print(f\"Batch statistics:\")\n",
    "    print(f\"  X range: {X_batch.min():.3f} to {X_batch.max():.3f}\")\n",
    "    print(f\"  y range: {y_batch.min():.3f} to {y_batch.max():.3f}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ai.model import CircuitPredictor, test_model\n",
    "\n",
    "# Test model\n",
    "model = test_model()\n",
    "\n",
    "# Test forward pass with actual data\n",
    "X_sample = X_batch[:8]  # First 8 samples\n",
    "y_sample = y_batch[:8]\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_sample)\n",
    "    \n",
    "print(\"\\nüß™ Sample predictions:\")\n",
    "for i in range(4):\n",
    "    print(f\"  Sample {i}: Actual={y_sample[i]:.3f}, Predicted={predictions[i].item():.3f}, Error={abs(y_sample[i]-predictions[i].item()):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train the Model\n",
    "\n",
    "**Options:**\n",
    "1. **Run full training** (next cell, ~2-3 hours)\n",
    "2. **Quick test** (5 epochs, ~15 minutes)\n",
    "3. **Load pre-trained** (if already trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 1: Full training (50 epochs, ~2-3 hours)\n",
    "# Uncomment to run\n",
    "\"\"\"\n",
    "from src.ai.train import Trainer\n",
    "trainer = Trainer()\n",
    "best_r2 = trainer.train()\n",
    "\"\"\"\n",
    "\n",
    "# OPTION 2: Quick test (5 epochs, ~15 minutes)\n",
    "from src.ai.train import Trainer\n",
    "\n",
    "# Create config for quick test\n",
    "quick_config = {\n",
    "    'epochs': 5,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.001,\n",
    "    'weight_decay': 0.0001,\n",
    "    'dropout_rate': 0.2,\n",
    "    'patience': 3,\n",
    "    'early_stopping_patience': 5,\n",
    "    'checkpoint_frequency': 2,\n",
    "}\n",
    "\n",
    "print(\"üöÄ Starting quick training (5 epochs)...\")\n",
    "trainer = Trainer(quick_config)\n",
    "best_r2 = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from src.ai.evaluate import ModelEvaluator\n",
    "\n",
    "# Check if model exists\n",
    "model_path = Path(\"../models/final/circuit_predictor_latest.pt\")\n",
    "if model_path.exists():\n",
    "    print(f\"‚úÖ Found trained model: {model_path}\")\n",
    "    evaluator = ModelEvaluator()\n",
    "    evaluator.main()\n",
    "else:\n",
    "    print(f\"‚ùå No trained model found at {model_path}\")\n",
    "    print(\"   Run the training cell above first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training history\n",
    "import pandas as pd\n",
    "\n",
    "history_path = Path(\"../results/logs/phase2/training_history.csv\")\n",
    "if history_path.exists():\n",
    "    history_df = pd.read_csv(history_path)\n",
    "    \n",
    "    print(\"üìä Training History:\")\n",
    "    print(history_df.tail())  # Last few epochs\n",
    "    \n",
    "    # Best R¬≤\n",
    "    best_r2 = history_df['val_r2'].max()\n",
    "    best_epoch = history_df['val_r2'].idxmax() + 1\n",
    "    \n",
    "    print(f\"\\nüèÜ Best Validation R¬≤: {best_r2:.4f} at epoch {best_epoch}\")\n",
    "    print(f\"üéØ Target: R¬≤ > 0.92\")\n",
    "    print(f\"‚úÖ Status: {\"ACHIEVED\" if best_r2 > 0.92 else \"NOT ACHIEVED\"}\")\n",
    "    \n",
    "    # Plot progress\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    axes[0].plot(history_df['epoch'], history_df['val_loss'], 'b-', label='Validation Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss (MSE)')\n",
    "    axes[0].set_title('Validation Loss over Time')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].plot(history_df['epoch'], history_df['val_r2'], 'g-', label='Validation R¬≤')\n",
    "    axes[1].axhline(y=0.92, color='r', linestyle='--', label='Target (0.92)')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('R¬≤ Score')\n",
    "    axes[1].set_title('Validation R¬≤ over Time')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No training history found. Train the model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create backup of Phase 2 progress\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "def create_phase2_backup():\n",
    "    \"\"\"Create backup of Phase 2 work\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "    backup_name = f\"qagnn_phase2_progress_{timestamp}\"\n",
    "    backup_path = Path(f\"../../project_backups/{backup_name}\")\n",
    "    \n",
    "    # Create backup directory\n",
    "    backup_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Copy important files\n",
    "    directories_to_backup = [\n",
    "        \"../models\",\n",
    "        \"../results/figures/process/phase2\",\n",
    "        \"../results/logs/phase2\",\n",
    "        \"../results/tables\",\n",
    "        \"../data/processed/phase2\",\n",
    "        \"../src/ai\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"üíæ Creating backup: {backup_path}\")\n",
    "    \n",
    "    for dir_path in directories_to_backup:\n",
    "        source = Path(dir_path)\n",
    "        if source.exists():\n",
    "            dest = backup_path / source.name\n",
    "            if source.is_dir():\n",
    "                shutil.copytree(source, dest, dirs_exist_ok=True)\n",
    "                print(f\"  ‚úÖ {source.name}: Copied\")\n",
    "            else:\n",
    "                shutil.copy2(source, dest)\n",
    "                print(f\"  ‚úÖ {source.name}: Copied\")\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è  {source}: Not found\")\n",
    "    \n",
    "    # Also copy this notebook\n",
    "    notebook_path = Path(\"./02_deep_learning.ipynb\")\n",
    "    if notebook_path.exists():\n",
    "        shutil.copy2(notebook_path, backup_path / \"02_deep_learning.ipynb\")\n",
    "        print(f\"  ‚úÖ Notebook: Copied\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Backup complete: {backup_path}\")\n",
    "    return backup_path\n",
    "\n",
    "# Create backup (optional)\n",
    "# backup_path = create_phase2_backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ NEXT STEPS FOR PHASE 2:\")\n",
    "print(\"=\" * 40)\n",
    "print(\"\"\"\n",
    "If R¬≤ > 0.92 achieved:\n",
    "  1. ‚úÖ Run full 50-epoch training\n",
    "  2. ‚úÖ Complete all evaluations\n",
    "  3. ‚úÖ Generate all visualizations\n",
    "  4. ‚úÖ Create backup\n",
    "  5. üöÄ Proceed to Phase 3: Quantum Optimization\n",
    "\n",
    "If R¬≤ < 0.92:\n",
    "  1. üîß Adjust model architecture\n",
    "  2. üìà Train for more epochs\n",
    "  3. üéõÔ∏è  Tune hyperparameters\n",
    "  4. üîç Check data quality\n",
    "  5. üîÑ Re-train with improvements\n",
    "\"\"\")\n",
    "\n",
    "# Check current status\n",
    "history_path = Path(\"../results/logs/phase2/training_history.csv\")\n",
    "if history_path.exists():\n",
    "    history_df = pd.read_csv(history_path)\n",
    "    best_r2 = history_df['val_r2'].max()\n",
    "    \n",
    "    print(f\"\\nüìä CURRENT STATUS:\")\n",
    "    print(f\"   Best R¬≤: {best_r2:.4f}\")\n",
    "    print(f\"   Target: >0.92\")\n",
    "    print(f\"   Gap: {0.92 - best_r2:.4f}\")\n",
    "    \n",
    "    if best_r2 > 0.92:\n",
    "        print(\"\\n‚úÖ READY FOR PHASE 3!\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  NEEDS IMPROVEMENT - Adjust and re-train.\")\n",
    "else:\n",
    "    print(\"\\nüîß No training completed yet. Run training cell above.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (qagnn)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
